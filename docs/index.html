<!DOCTYPE html>
<html>
  <head>
    <title>Improving Multi-lingual Language Understanding Through Contextualized Transfer Learning</title>
    <meta charset="utf-8">
    <meta name="author" content="Ali Zaidi" />
    <meta name="date" content="2018-07-03" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Improving Multi-lingual Language Understanding Through Contextualized Transfer Learning
## Towards Unsupervised Machine Translation
### Ali Zaidi
### 2018-07-03

---






class: inverse


## whoami

.pull-left[

![](imgs/stupendousman.jpeg)

]

.pull-right[

* Ali Zaidi
* ![](https://github.com/carlsednaoui/gitsocial/raw/master/assets/icons%20without%20padding/github.png) akzaidi, ![](https://github.com/carlsednaoui/gitsocial/raw/master/assets/icons%20without%20padding/twitter.png) alikzaidi, ![](https://i.imgur.com/nn1V2fR.png) sheikhyerbooty
* From: DC, Ghana, Kyrgyzstan, Pakistan, Toronto, NYC, Bay Area
* Work: Microsoft (prior: Revolution Analytics, NERA)
* Student: Stanford (prior: University of Toronto)
* Interests: Food, Music, Stochastic Analysis, Languages, NLP, Reinforcement Learning

]

--
* Interests for the camp: meeting cool people and learning about you, your favorite music and food, and maybe a few phrases from you native languages!
* Transfer learning in NLP
* Multi-task learning in NLP
* Structured prediction models: semantic indexing, relation extraction
* Grounded language learning in Minecraft

---

background-image: url("https://media.giphy.com/media/1M9fmo1WAFVK0/giphy.gif")
background-size: cover

---

## Capacity and Inductive Biases
### Learning Curves

![](imgs/learning-curves.png)

---


## Data Scarcity, Non-generalizeable Features


Dataset | Domain | Size (#sentences)
---------|----------|---------
 CoNLL 2003 | NER | 15K
 OntoNotes | Coreference Resolution | 75K
 PTB | Parsing | 40K
 SQuAD | QA | 100K
 SNLI | Entailment | 570K
 SST | Sentiment | 10K

- Most SOTA NLP results are obtained by training end-to-end architectures for each language task. 
- Most datasets are in English, and are very small.
- I'd like examine how transformer models and convolutional modules such as QANet can be used as generative language models
- Can we fine-tune these language models for text classification and multi-task problems? 
- Is the combination of transformer/convolutional architectures + structured prediction models an effective representation for multi-lingual transfer learning?

---

## Recent Approaches

### Fine-Tuning Language Models

1. [OpenAI: Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/)
    * **_tldr_**: Train an unsupervised language model using a transformer architecture, and then fine-tune on task-specific datasets.
2. [fastAI: Universal Language Model Fine-tuning for Text Classification](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)
    * **_tldr_**: Pre-train a language model on large unlabelled corpus. Initialize new language model on your unlabeled domain-specific corpus. Fine-tune task-domain-specific architecture for text classification.
    ![](imgs/ulmfit.png)

---

## Recent Approaches

### Comprehension Models and Multi-task Networks

3. [Google Brain: QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension](https://arxiv.org/pdf/1804.09541.pdf)
    - **_tldr_**: Transformer based Q&amp;A model consisting solely of convolutions and self-attentions.
4. [AllenAI: Deep Contextualized Word Vectors](https://arxiv.org/abs/1802.05365)
    - **_tldr_**: Train a generic language model using Bidirectional-LSTM and iteratively fine-tune contextual vectors.
5. [Salesforce Research, The Natural Language Decathlon](https://einstein.ai/research/the-natural-language-decathlon)
    - **_tldr_**: Challenge consisting of ten NLP tasks. Proposed MQAN: bidirectional LSTM, dual coattention, + additional two BiLSTMs + self-attention.
    
    
---

## MQAN Architecture

![](https://einstein.ai/static/images/pages/research/decaNLP/MQAN.png)

---

## Zero Shot Transfer

- Can we transfer to new tasks with a single or zero examples?
- If the language model is truly generalizable then single shot or zero shot transfer is possible!

--

![](imgs/openai-zeroshot.png)

---
    

## Adversarial Alignment 

--

![](imgs/muse-alignment.png)

--

`$$\mathcal{L}_{\mathcal{D}}\left(\theta_{\mathcal{D}}\vert\boldsymbol{W}\right)=-\frac{1}{n}\sum_{i=1}^{n}\log P_{\theta_{\mathcal{D}}}\left({\rm source}=1\vert W_{x_{i}}\right)-\frac{1}{m}\sum_{i=1}^{m}\log P_{\theta_{\mathcal{D}}}\left({\rm source}=0\vert y_{i}\right)$$`

---

## Adversarial Alignment

### Shared English-Russian Embeddings

![](imgs/en-ruski-muse.png)

---

## Global Graph Embeddings
### Generalize with Graph Convolutional Networks

![](imgs/glomo-embeddings.png)


---

class: center
background-image: url(https://media.giphy.com/media/falTqLTgSgmas/giphy.gif)
background-size: cover

# Thanks!

- [Thanks to my mentor Minjoon Seo!](https://seominjoon.github.io/)
[`https://github.com/akzaidi/fine-lm`](https://github.com/akzaidi/fine-lm)
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
